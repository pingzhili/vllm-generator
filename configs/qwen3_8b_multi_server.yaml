# Configuration for multiple vLLM servers with Qwen models

data:
  input_path: "/root/open-math-reasoning/sample_10.parquet"
  output_path: "/root/open-math-reasoning/sample_10_results_repeat_.parquet"
  input_column: "problem"
  output_column: "response"

models:
  # Multiple Qwen model endpoints for load balancing
  - url: "http://localhost:8000"
    name: "qwen3-8b-server-0"
  - url: "http://localhost:8001"
    name: "qwen3-8b-server-1"
  - url: "http://localhost:8002"
    name: "qwen3-8b-server-2"
  - url: "http://localhost:8003"
    name: "qwen3-8b-server-3"
  - url: "http://localhost:8004"
    name: "qwen3-8b-server-4"
  - url: "http://localhost:8005"
    name: "qwen3-8b-server-5"
  - url: "http://localhost:8006"
    name: "qwen3-8b-server-6"
  - url: "http://localhost:8007"
    name: "qwen3-8b-server-7"


generation:
  num_samples: 8
  temperature: 0.6
  top_p: 0.95
  top_k: 20
  max_tokens: 32768


processing:
  batch_size: 4
  num_workers: 16
  checkpoint_interval: 100
  checkpoint_dir: "./checkpoints/qwen_run"
  resume: false

retry:
  max_retries: 3
  retry_delay: 1.0
  timeout: 300
  backoff_factor: 2.0

logging:
  level: "INFO"
  file: "logs/qwen_generation.log"
  format: "{time:YYYY-MM-DD HH:mm:ss} | {level} | {name}:{function}:{line} | {message}"
  rotation: "1 day"
  retention: "14 days"