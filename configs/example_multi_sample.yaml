# Configuration for multiple samples per question

data:
  input_path: "data/questions.parquet"
  output_path: "data/multi_sample_responses.parquet"
  input_column: "question"
  output_column: "response"

model:
  url: "http://localhost:8000"

generation:
  num_samples: 3
  temperature: [0.7, 0.9, 1.1]  # Different temperature per sample
  max_tokens: 1024

processing: {}

logging:
  level: "INFO"